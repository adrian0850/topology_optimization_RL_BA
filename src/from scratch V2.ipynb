{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import autograd.numpy as anp\n",
    "import scipy\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common import results_plotter\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, VecMonitor\n",
    "\n",
    "%load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "\n",
    "import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 5                             # The height of the design space\n",
    "width = 10                              # The width of the design space                   \n",
    "number_of_nodes = height * width        # The number of nodes in the design space\n",
    "bound_nodes_list = [(0, 0), (-1, 0)]    # A list containing the coordinates of \n",
    "                                        # the bounded nodes\n",
    "loaded_nodes_list = [(-1, -1)]           # A list containing the coordinates of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHYSICAL PARAMETERS FOR THE FEM ANALYSIS\n",
    "filter_width = 1\n",
    "penal = 3.0\n",
    "young_min = 1e-9\n",
    "young = 1\n",
    "poisson = 0.3\n",
    "density = 1e-4\n",
    "constraint_thresh = 0.5\n",
    "\n",
    "\n",
    "_DESIGN = 0\n",
    "_BOUND = 1\n",
    "_FORCE = 2\n",
    "_COMPLIANCE = 3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TECHNICAL PARAMETERS FOR THE REINFORCEMENT LEARNING\n",
    "\n",
    "number_subprocesses = 16     # The number of Threads to be used during the \n",
    "                            # learning process\n",
    "\n",
    "log_dir = \"log/\"            # The directory of where to save the best model\n",
    "ts_board_dir = \"ts_board/\"  # The directory of where to save the tensorboard files\n",
    "\n",
    "ts = 5e6                    # The number of timesteps to be used during the \n",
    "                            # learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for the used FEM analysis taken from the Gigala repository\n",
    "# it saves the boundary nodes in a 3D array where the first two dimensions are \n",
    "# the coordinates of the node and the third dimension is the direction of the normal\n",
    "normals = np.zeros((height + 1, width + 1, 2))\n",
    "x = 0\n",
    "y = 1\n",
    "for coords in bound_nodes_list:\n",
    "    normals[coords[y], coords[x], x] = 1\n",
    "    normals[coords[y], coords[x], y] = 1\n",
    "\n",
    "forces = np.zeros((height + 1, width + 1, 2))\n",
    "forces[-1, -1, y] = -1\n",
    "forces = forces.ravel()\n",
    "\n",
    "fixdofs = np.flatnonzero(normals.ravel())\n",
    "alldofs = np.arange(2 * (normals.shape[0]) * (normals.shape[1]))\n",
    "freedofs = np.sort(list(set(alldofs) - set(fixdofs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colormap for the plots\n",
    "mpl.rcParams['image.cmap'] = 'YlOrBr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x, freedofs, fixdofs, forces, volume_contraint=False, use_filter=True):\n",
    "    \"\"\"\"Objective function for the topology optimization problem.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy.ndarray\n",
    "        The design space.\n",
    "    volume_contraint : bool, optional\n",
    "        Whether to use the volume constraint.\n",
    "    use_filter : bool, optional\n",
    "        Whether to use the filter.\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The compliance of the design space.\n",
    "    \"\"\"\n",
    "    kwargs = dict(penal=penal, e_min=young_min, e_0=young)\n",
    "    x_phys = physical_density(x, volume_contraint=volume_contraint, use_filter=use_filter)\n",
    "    ke     = get_stiffness_matrix(young, poisson)\n",
    "    u      = displace(x_phys, ke, forces, freedofs, fixdofs, **kwargs)\n",
    "    c      = compliance(x_phys, u, ke, **kwargs)\n",
    "    return c\n",
    "\n",
    "\n",
    "def get_compliance(state, freedofs, fixdofs, forces):\n",
    "    \"\"\"This Function Provides an easy way to get the compliance of a state\"\"\"\n",
    "    design = state[:, :, _DESIGN]\n",
    "\n",
    "\n",
    "    reshape = lambda x: x.reshape(height, width)\n",
    "    objective_fn = lambda x: objective(reshape(x), freedofs, fixdofs, forces)\n",
    "    value = objective_fn(design)\n",
    "    return value\n",
    "\n",
    "def get_compliance_per_element(state, freedofs, fixdofs, forces):\n",
    "    \"\"\"This Function Provides an easy way to get the compliance of a state\"\"\"\n",
    "    design = state[:, :, _DESIGN]\n",
    "    reshape = lambda state: state.reshape(height, width)\n",
    "    objective_fn = lambda state: objective_for_compliance_per_element(reshape(state), freedofs, fixdofs, forces)\n",
    "    value = objective_fn(state)\n",
    "    return value\n",
    "\n",
    "def objective_for_compliance_per_element(x, freedofs, fixdofs, forces, volume_contraint=False, use_filter=True):\n",
    "    \"\"\"\"Objective function for the topology optimization problem.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy.ndarray\n",
    "        The design space.\n",
    "    volume_contraint : bool, optional\n",
    "        Whether to use the volume constraint.\n",
    "    use_filter : bool, optional\n",
    "        Whether to use the filter.\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The compliance of the design space.\n",
    "    \"\"\"\n",
    "    kwargs = dict(penal=penal, e_min=young_min, e_0=young)\n",
    "    x_phys = physical_density(x, volume_contraint=volume_contraint, use_filter=use_filter)\n",
    "    ke     = get_stiffness_matrix(young, poisson)\n",
    "    u      = displace(x_phys, ke, forces, freedofs, fixdofs, **kwargs)\n",
    "    c      = compliance_per_element(x_phys, u, ke, **kwargs)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the FEM function written by Gigala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_solver(a_entries, a_indices, size, sym_pos):\n",
    "    # a is (usu.) symmetric positive; could solve 2x faster w/sksparse.cholmod.cholesky(a).solve_A\n",
    "    \n",
    "    a = scipy.sparse.coo_matrix((a_entries, a_indices), shape=(size,)*2).tocsc()\n",
    "\n",
    "    return scipy.sparse.linalg.splu(a).solve\n",
    "\n",
    "\n",
    "\n",
    "# @autograd.primitive\n",
    "def solve_coo(a_entries, a_indices, b, sym_pos=False):\n",
    "    solver = _get_solver(a_entries, a_indices, b.size, sym_pos)\n",
    "    return solver(b)\n",
    "\n",
    "def grad_solve_coo_entries(ans, a_entries, a_indices, b, sym_pos=False):\n",
    "    def jvp(grad_ans):\n",
    "        lambda_ = solve_coo(a_entries, a_indices if sym_pos else a_indices[::-1],\n",
    "                            grad_ans, sym_pos)\n",
    "        i, j = a_indices\n",
    "        return -lambda_[i] * ans[j]\n",
    "    return jvp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compliance_per_element(x_phys, u, ke, *, penal=3, e_min=1e-9, e_0=1):\n",
    "    nely, nelx = x_phys.shape\n",
    "    ely, elx = anp.meshgrid(range(nely), range(nelx))  # x, y coords for the index map\n",
    "\n",
    "    n1 = (nely+1)*(elx+0) + (ely+0)  # nodes\n",
    "    n2 = (nely+1)*(elx+1) + (ely+0)\n",
    "    n3 = (nely+1)*(elx+1) + (ely+1)\n",
    "    n4 = (nely+1)*(elx+0) + (ely+1)\n",
    "    all_ixs = anp.array([2*n1, 2*n1+1, 2*n2, 2*n2+1, 2*n3, 2*n3+1, 2*n4, 2*n4+1])\n",
    "    u_selected = u[all_ixs]  # select from u matrix\n",
    "\n",
    "    ke_u = anp.einsum('ij,jkl->ikl', ke, u_selected)  # compute x^penal * U.T @ ke @ U\n",
    "    ce = anp.einsum('ijk,ijk->jk', u_selected, ke_u)\n",
    "    C = young_modulus(x_phys, e_0, e_min, p=penal) * ce.T\n",
    "    return C  \n",
    "    \n",
    "def compliance(x_phys, u, ke, *, penal=3, e_min=1e-9, e_0=1):\n",
    "    C = compliance_per_element(x_phys, u, ke, penal=penal, e_min=e_min, e_0=e_0)\n",
    "    return anp.sum(C)\n",
    "\n",
    "def get_stiffness_matrix(e, nu):  # e=young's modulus, nu=poisson coefficient\n",
    "    k = anp.array([1/2-nu/6, 1/8+nu/8, -1/4-nu/12, -1/8+3*nu/8,\n",
    "                -1/4+nu/12, -1/8-nu/8, nu/6, 1/8-3*nu/8])\n",
    "    return e/(1-nu**2)*anp.array([[k[0], k[1], k[2], k[3], k[4], k[5], k[6], k[7]],\n",
    "                               [k[1], k[0], k[7], k[6], k[5], k[4], k[3], k[2]],\n",
    "                               [k[2], k[7], k[0], k[5], k[6], k[3], k[4], k[1]],\n",
    "                               [k[3], k[6], k[5], k[0], k[7], k[2], k[1], k[4]],\n",
    "                               [k[4], k[5], k[6], k[7], k[0], k[1], k[2], k[3]],\n",
    "                               [k[5], k[4], k[3], k[2], k[1], k[0], k[7], k[6]],\n",
    "                               [k[6], k[3], k[4], k[1], k[2], k[7], k[0], k[5]],\n",
    "                               [k[7], k[2], k[1], k[4], k[3], k[6], k[5], k[0]]])\n",
    "\n",
    "\n",
    "def get_k(stiffness, ke):\n",
    "    # Constructs sparse stiffness matrix k (used in the displace fn)\n",
    "    # First, get position of the nodes of each element in the stiffness matrix\n",
    "    nely, nelx = stiffness.shape\n",
    "    ely, elx = anp.meshgrid(range(nely), range(nelx))  # x, y coords\n",
    "    ely, elx = ely.reshape(-1, 1), elx.reshape(-1, 1)\n",
    "\n",
    "    n1 = (nely+1)*(elx+0) + (ely+0)\n",
    "    n2 = (nely+1)*(elx+1) + (ely+0)\n",
    "    n3 = (nely+1)*(elx+1) + (ely+1)\n",
    "    n4 = (nely+1)*(elx+0) + (ely+1)\n",
    "    edof = anp.array([2*n1, 2*n1+1, 2*n2, 2*n2+1, 2*n3, 2*n3+1, 2*n4, 2*n4+1])\n",
    "    edof = edof.T[0]\n",
    "    x_list = anp.repeat(edof, 8)  # flat list pointer of each node in an element\n",
    "    y_list = anp.tile(edof, 8).flatten()  # flat list pointer of each node in elem\n",
    "\n",
    "    # make the global stiffness matrix K\n",
    "    kd = stiffness.T.reshape(nelx*nely, 1, 1)\n",
    "    value_list = (kd * anp.tile(ke, kd.shape)).flatten()\n",
    "    return value_list, y_list, x_list\n",
    "\n",
    "def displace(x_phys, ke, forces, freedofs, fixdofs, *, penal=3, e_min=1e-9, e_0=1):\n",
    "    # Displaces the load x using finite element techniques (solve_coo=most of runtime)\n",
    "    stiffness = young_modulus(x_phys, e_0, e_min, p=penal)\n",
    "    k_entries, k_ylist, k_xlist = get_k(stiffness, ke)\n",
    "\n",
    "    index_map, keep, indices = _get_dof_indices(freedofs, fixdofs, k_ylist, k_xlist)\n",
    "\n",
    "\n",
    "    u_nonzero = solve_coo(k_entries[keep], indices, forces[freedofs], sym_pos=True)\n",
    "    u_values = anp.concatenate([u_nonzero, anp.zeros(len(fixdofs))])\n",
    "    return u_values[index_map]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def young_modulus(x, e_0, e_min, p=3):\n",
    "    return e_min + x ** p * (e_0 - e_min)\n",
    "\n",
    "def physical_density(x,volume_contraint=False, use_filter=True):\n",
    "    x = 1 * x.reshape(height, width)  # reshape from 1D to 2D\n",
    "    return gaussian_filter(x, filter_width) if use_filter else x  # maybe filter\n",
    "\n",
    "def mean_density(x, volume_contraint=False, use_filter=True):\n",
    "    return anp.mean(physical_density(x, volume_contraint, use_filter))\n",
    "\n",
    "# @autograd.extend.primitive\n",
    "def gaussian_filter(x, width): # 2D gaussian blur/filter\n",
    "    return scipy.ndimage.gaussian_filter(x, width, mode='reflect')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _get_dof_indices(freedofs, fixdofs, k_xlist, k_ylist):\n",
    "    index_map = inverse_permutation(anp.concatenate([freedofs, fixdofs]))\n",
    "    keep = anp.isin(k_xlist, freedofs) & anp.isin(k_ylist, freedofs)\n",
    "    # Now we index an indexing array that is being indexed by the indices of k\n",
    "    i = index_map[k_ylist][keep]\n",
    "    j = index_map[k_xlist][keep]\n",
    "    return index_map, keep, anp.stack([i, j])\n",
    "\n",
    "def inverse_permutation(indices):  # reverses an index operation\n",
    "    inverse_perm = np.zeros(len(indices), dtype=anp.int64)\n",
    "    inverse_perm[indices] = np.arange(len(indices), dtype=anp.int64)\n",
    "    return inverse_perm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewardFunction_old(state):\n",
    "    # This is the Reward Function designed by Gigala\n",
    "    reshape = lambda state: state.reshape(height, width)\n",
    "    objective_fn = lambda state: objective(reshape(state))\n",
    "    value = objective_fn(state)\n",
    "    return ((1/value)**0.5) *10\n",
    "\n",
    "def rewardFunction_1(matrix):\n",
    "    # This a \"naive\" Reward Function designed by me\n",
    "    reshape = lambda state: state.reshape(height, width)\n",
    "    objective_fn = lambda state: objective(reshape(state))\n",
    "    value = objective_fn(matrix)\n",
    "    reward = 20 / (np.sqrt(value)) / (constraintFunction(matrix))\n",
    "    return round(reward, 5)\n",
    "\n",
    "def rewardFunction_2(matrix, current_compliance, initial_compliance, last_compliance):\n",
    "    # this is the Reward Function by Nathan Brown modified to fit the different\n",
    "    # design space and different values used\n",
    "    comp_frac = ((initial_compliance/current_compliance))**2\n",
    "    removed_node_frac = (get_removed_cells(matrix) / number_of_nodes)**2\n",
    "    comp_frac_2 = current_compliance / last_compliance\n",
    "    size_scalar = matrix.size / 50\n",
    "    return (comp_frac + removed_node_frac - (comp_frac_2 / 100)) * size_scalar\n",
    "\n",
    "def get_filled_cells(matrix):\n",
    "    return sum(cell == 1 for row in matrix for cell in row)\n",
    "\n",
    "def get_removed_cells(matrix):\n",
    "    return sum(cell == density for row in matrix for cell in row)\n",
    "\n",
    "def is_continuous(matrix, targets):\n",
    "    if not targets:\n",
    "        return False\n",
    "    filled_cells = get_filled_cells(matrix)\n",
    "    visited = dfs(matrix, targets)\n",
    "    return False if len(visited) == 0 else len(visited) == filled_cells\n",
    " \n",
    "\n",
    "def dfs(matrix, targets):\n",
    "    \"\"\"This function is the depth first search algorithm that is used to check \n",
    "    if all the filled cells in the design space are connected to a specified \n",
    "    start point.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    matrix : numpy.ndarray\n",
    "        The design space.\n",
    "    start : tuple\n",
    "        The coordinates of the start point.\n",
    "    targets : tuple\n",
    "        The coordinates of the end point.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    set\n",
    "        The set containing the visited nodes.\"\"\"\n",
    "    targets_copy = convert_all(targets.copy(), (height, width))\n",
    "    start = targets_copy.pop(0)\n",
    "    rows, cols = len(matrix), len(matrix[0]) \n",
    "    visited = set() # Set to keep track of visited nodes    \n",
    "    stack = [start] # Start the stack with the start node\n",
    "    if not stack:  # Check if the stack is empty\n",
    "        raise RuntimeError(\"The stack is empty\")\n",
    "    while stack:\n",
    "        (row, col) = stack.pop()    # pop the last coordinates from the stack\n",
    "        if (row < 0 or \n",
    "            row >= rows or \n",
    "            col < 0 or \n",
    "            col >= cols or \n",
    "            (row, col) in visited or \n",
    "            matrix[row][col] == density): \n",
    "            #checking for discarding conditions\n",
    "            continue\n",
    "        if (row, col) in targets_copy:\n",
    "\n",
    "            targets_copy.remove((row, col))\n",
    "        visited.add((row, col))     # Add the current node to the visited set\n",
    "        stack.extend([(row-1, col), (row+1, col), (row, col-1), (row, col+1),\n",
    "                      (row-1, col-1), (row-1, col+1), (row+1, col-1), (row+1, col+1)])\n",
    "        # Add the neighbours of the current node to the stack\n",
    " \n",
    "    return visited if not targets_copy else []\n",
    "\n",
    "def convert_relative_to_absolute(coord, matrix_dim):\n",
    "    \"\"\"\n",
    "    Convert relative indices in a coordinate to absolute indices.\n",
    "\n",
    "    Parameters:\n",
    "    coord (tuple): The coordinate with potentially relative indices.\n",
    "    matrix_dim (tuple): The dimensions of the matrix.\n",
    "\n",
    "    Returns:\n",
    "    tuple: The coordinate with absolute indices.\n",
    "    \"\"\"\n",
    "    return tuple(dim + i if i < 0 else i for i, dim in zip(coord, matrix_dim))\n",
    "\n",
    "def convert_all(coords, matrix_dim):\n",
    "    \"\"\"\n",
    "    Convert all relative indices in a list of coordinates to absolute indices.\n",
    "\n",
    "    Parameters:\n",
    "    coords (list): The list of coordinates with potentially relative indices.\n",
    "    matrix_dim (tuple): The dimensions of the matrix.\n",
    "\n",
    "    Returns:\n",
    "    list: The list of coordinates with absolute indices.\n",
    "    \"\"\"\n",
    "    return list(map(lambda coord: convert_relative_to_absolute(coord, matrix_dim), coords))\n",
    "\n",
    "def constraintFunction(state):\n",
    "    reshape = lambda state: state.reshape(height, width)\n",
    "    constraint = lambda params: mean_density(reshape(params)) \n",
    "    const = constraint(state)\n",
    "    return const\n",
    "\n",
    "\n",
    "x_bound_positions_for_scatter = [coord[1] for coord in convert_all(bound_nodes_list, (height, width))]\n",
    "y_bound_positions_for_scatter = [coord[0] for coord in convert_all(bound_nodes_list, (height, width))]\n",
    "\n",
    "x_loaded_positions_for_scatter = [coord[1] for coord in convert_all(loaded_nodes_list, (height, width))], \n",
    "y_loaded_positions_for_scatter = [coord[0] for coord in convert_all(loaded_nodes_list, (height, width))], "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thoughts on training rewards\n",
    "## Positive rewards\n",
    "- While an Episode has not yet ended, we will, continuously, with each step that gets made, add to the Reward Variable.\n",
    "- The Reward should mainly come from a Function, that calculates the physical properties of the Design, and evaluates them while taking into Consideration the \"weight\" of the design\n",
    "- For this we have available the Compliance function by Gigala as well as his Constraint Function\n",
    "\n",
    "## Quitting criteria\n",
    "All of these should also give a senseful negative reward and end the current Episode\n",
    "\n",
    "- if the action would result in the Design space no longer being continous\n",
    "- if the action has already been executed\n",
    "- if the action would remove a bounded or loaded node\n",
    "\n",
    "\n",
    "\n",
    "## Reward Function used by Nathan Brown: \n",
    "$r_{ts}=\\left(\\frac{c_0}{c_t}\\right)^{2}+\\left(\\frac{\\alpha_t}{N^{2}}\\right)^2$\n",
    "- $c_s$ is the inital strain Energy of a wholey filled in Design Space,\n",
    "- $c_t$ is the strain Energy of the Design Space at the current Timestep,\n",
    "- $\\alpha_t$ is the number of removed elements at this timestep\n",
    "- $N^{2}$ is the Dimension of the quadratic Design Space used by Nathan Brown\n",
    "\n",
    "We can try to modify it for our Optimization in the following way:<br>\n",
    "$r_{ts}=\\left(\\frac{2*comp_0}{2*comp_t}\\right)^{2}+\\left(\\frac{\\alpha_t}{l*w}\\right)^2=\\left(\\frac{comp_0}{copm_t}\\right)^{2}+\\left(\\frac{\\alpha_t}{l*w}\\right)^2$ because: $strain  energy = \\frac{1}{2}*compliance$\n",
    "- $comp_0$ is the inital compliance of a wholey filled in Design Space,\n",
    "- $c_t$ is the compliance of the Design Space at the current Timestep,\n",
    "- $\\alpha_t$ is the number of removed elements at this timestep\n",
    "- $l$ is the length of our Design Space\n",
    "- $w$ is the width of our Design Space\n",
    "<br>\n",
    "### The Relation between Strain Energy and Compliance can be dereived as follows\n",
    "- compliance is defined as:\n",
    "$$C=F^Tu$$\n",
    "where $F$ is the Force Vector and $u$ is the Displacement Vector\n",
    "- Strain Energy is defined as:\n",
    "$$U=\\frac{1}{2}u^TKu$$\n",
    "where $K$ represents the stiffnes matrix\n",
    "- using the equation of the stiffnes matrix $Ku=F$, displacement can be expressed as:\n",
    "$$u=K^{-1}F$$\n",
    "- now we substitute $u=K^{-1}F$ into our Compliance Function:\n",
    "$$C=F^Tu=F^TK^{-1}F$$\n",
    "- now we do the same for our strain energy equation\n",
    "$$U=\\frac{1}{2}u^TKu=\\frac{1}{2}\\left(K^{-1}F\\right)^TK\\left(K^{-1}F\\right)=\\frac{1}{2}F^TK^{-1}F$$\n",
    "- we now see, that we can substitue in the compliance function as Follows\n",
    "$$\\frac{1}{2}F^TK^{-1}F=\\frac{1}{2}C$$\n",
    "- Thus we have the relation between the strain Energy and compliance, and can\n",
    "modify the function used in NathanBrown's Topology Optimization for our Code\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_compliance() missing 3 required positional arguments: 'freedofs', 'fixdofs', and 'forces'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 100\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mwhere(matrix \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, density, matrix)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# create the initial compliance of a completely filled in design space\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m initial_compliance \u001b[38;5;241m=\u001b[39m \u001b[43mget_compliance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Here we initialize the bound node matrix as well as the states and matrices list\u001b[39;00m\n\u001b[0;32m    103\u001b[0m bound_nodes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((height, width))\n",
      "\u001b[1;31mTypeError\u001b[0m: get_compliance() missing 3 required positional arguments: 'freedofs', 'fixdofs', and 'forces'"
     ]
    }
   ],
   "source": [
    "#TESTING\n",
    "\n",
    "def scale_matrix(matrix, target_rows, target_cols):\n",
    "    original_rows = len(matrix)\n",
    "    original_cols = len(matrix[0]) if original_rows > 0 else 0\n",
    "    \n",
    "    # Calculate scale factors\n",
    "    row_scale_factor = target_rows // original_rows\n",
    "    col_scale_factor = target_cols // original_cols\n",
    "    \n",
    "    # Scale the matrix\n",
    "    scaled_matrix = []\n",
    "    for row in matrix:\n",
    "        # Scale each row horizontally\n",
    "        scaled_row = []\n",
    "        for element in row:\n",
    "            scaled_row.extend([element] * col_scale_factor)\n",
    "        \n",
    "        # Scale the matrix vertically\n",
    "        for _ in range(row_scale_factor):\n",
    "            scaled_matrix.append(list(scaled_row))\n",
    "    \n",
    "    # Handle any remaining rows due to non-integer scale factors\n",
    "    additional_rows = target_rows % original_rows\n",
    "    if additional_rows > 0:\n",
    "        for i in range(additional_rows):\n",
    "            scaled_matrix.append(list(scaled_matrix[i]))\n",
    "    \n",
    "    # Handle any remaining columns due to non-integer scale factors\n",
    "    additional_cols = target_cols % original_cols\n",
    "    if additional_cols > 0:\n",
    "        for row in scaled_matrix:\n",
    "            row.extend(row[:additional_cols])\n",
    "    \n",
    "    return np.array(scaled_matrix)\n",
    "\n",
    "def render_all(states):\n",
    "    \"\"\"This function is used to render the different design spaces with their\n",
    "    respective reward functions and compliance values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    states : list\n",
    "        The list containing the different design spaces.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        None\n",
    "    \"\"\"\n",
    "    num_rows = 3\n",
    "    num_cols = 5\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(30, 23))\n",
    "    for i, state in enumerate(states):\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "        axs[row, col].imshow(states[i][\"matrix\"].reshape(height, width), vmin=density, vmax=1)\n",
    "        title = (state[\"Name\"]\n",
    "        + \"\\n\\nGigalaRewardFunc: \" + str(round(state[\"rewardfunc\"], 5))  \n",
    "        + \"\\nCompliance: \" + str(round(state[\"Compliance\"], 2))\n",
    "        + \"\\nConstraint: \" + str(round(state[\"constraint\"], 3)) \n",
    "        + \"\\nContinuous: \" + str(state[\"continuous\"])\n",
    "        + \"\\nFilled Cells: \" + str(state[\"filled_cells\"])\n",
    "        + \"\\nFilled Ratio: \" + str(round(state[\"filled_ratio\"], 3))\n",
    "        + \"\\nrelationRewardFunc: \" + str(round(state[\"reward1\"], 2))\n",
    "        + \"\\nmodifiedNathanBrown: \" + str(round(state[\"reward2\"],2)))\n",
    "        axs[row, col].scatter(x_bound_positions_for_scatter, \n",
    "                              y_bound_positions_for_scatter, \n",
    "                              s=150, color='k', marker='x')\n",
    "        axs[row, col].scatter(x_loaded_positions_for_scatter, \n",
    "                              y_loaded_positions_for_scatter, \n",
    "                              s=150, color='k', marker='$↓$')\n",
    "        axs[row, col].set_title(title, fontsize=18, pad=20)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def flip_random_elements(matrix):\n",
    "    matrix_copy = np.copy(matrix)\n",
    "    rows, cols = matrix_copy.shape\n",
    "    num_elements_to_flip = np.random.randint(1, rows*cols)\n",
    "    row_indices = np.random.randint(0, rows, num_elements_to_flip)\n",
    "    col_indices = np.random.randint(0, cols, num_elements_to_flip)\n",
    "    for row, col in zip(row_indices, col_indices):\n",
    "        matrix_copy[row, col] = 1 if matrix_copy[row, col] == density else density\n",
    "    return matrix_copy\n",
    "\n",
    "def turn_random_density_to_one(matrix):\n",
    "    matrix_copy = np.copy(matrix)\n",
    "    zero_indices = np.argwhere(matrix_copy == density)\n",
    "    if zero_indices.size == density:\n",
    "        return matrix_copy\n",
    "    random_index = zero_indices[np.random.choice(zero_indices.shape[0])]\n",
    "    matrix_copy[tuple(random_index)] = 1\n",
    "    return matrix_copy\n",
    "\n",
    "def zero_to_densitiy(matrix):\n",
    "    return np.where(matrix == 0, density, matrix)\n",
    "\n",
    "\n",
    "# create the initial compliance of a completely filled in design space\n",
    "initial_compliance = get_compliance(np.ones((height, width)))\n",
    "\n",
    "# Here we initialize the bound node matrix as well as the states and matrices list\n",
    "bound_nodes = np.zeros((height, width))\n",
    "for coord in bound_nodes_list:\n",
    "        bound_nodes[coord] = 1\n",
    "states = []\n",
    "matrices = []\n",
    "\n",
    "# Here we create the different matrices that we want to showcase\n",
    "# First a fully filled in Matrix\n",
    "filled_matrix = np.ones((height, width))\n",
    "matrices.append(filled_matrix)\n",
    "\n",
    "# An Empty Matrix\n",
    "empty_matrix = zero_to_densitiy(np.zeros((height, width)))\n",
    "matrices.append(zero_to_densitiy(empty_matrix))\n",
    "\n",
    "# A randomly generated Matrix\n",
    "random_matrix = np.random.choice([density, 1], (height, width))\n",
    "matrices.append(random_matrix)\n",
    "\n",
    "# A half filled in Matrix\n",
    "half_matrix = [[1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "               [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
    "               [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
    "               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
    "matrices.append(zero_to_densitiy(half_matrix))\n",
    "\n",
    "# A Matrix which represents a more or less ideal design\n",
    "ideal_matrix = [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
    "                [1, 1, 0, 0, 0, 1, 1, 1, 1, 0],\n",
    "                [0, 1, 1, 0, 1, 1, 0, 0, 1, 1],\n",
    "                [0, 0, 1, 1, 1, 0, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
    "matrices.append(zero_to_densitiy(ideal_matrix))\n",
    "\n",
    "# A Matrix which represents a worse design\n",
    "less_ideal_matrix = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
    "matrices.append(zero_to_densitiy(less_ideal_matrix))\n",
    "\n",
    "# A copy of the ideal design, with a break in it\n",
    "broken_matrix = [[1, 1, 1, 1, 1, 0, 1, 0, 0, 0],\n",
    "                 [0, 0, 1, 0, 0, 0, 1, 1, 0, 0],\n",
    "                 [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
    "                 [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
    "                 [1, 1, 1, 1, 1, 0, 1, 1, 1, 1]]\n",
    "matrices.append(zero_to_densitiy(broken_matrix))\n",
    "\n",
    "# A Matrix which represents a very elastic design\n",
    "bad_design = [[1, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "              [0, 0, 1, 0, 0, 0, 1, 1, 0, 0],\n",
    "              [0, 0, 0, 1, 0, 1, 0, 0, 1, 0],\n",
    "              [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
    "              [1, 1, 1, 1, 1, 0, 0, 0, 0, 1]]\n",
    "matrices.append(zero_to_densitiy(bad_design))\n",
    "\n",
    "# A matrix which represents a stiff but heavy design\n",
    "heavy_matrix = [[1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
    "                [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
    "                [1, 1, 1, 1, 1, 1, 0, 0, 1, 0],\n",
    "                [1, 1, 1, 1, 1, 0, 0, 0, 0, 1],\n",
    "                [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
    "matrices.append(zero_to_densitiy(heavy_matrix))\n",
    "\n",
    "# A copy of the ideal matrix with a crucial node missing\n",
    "close_call_matrix = zero_to_densitiy([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
    "                                      [0, 0, 1, 0, 0, 0, 1, 1, 0, 0],\n",
    "                                      [0, 0, 0, 1, 0, 1, 0, 0, 1, 0],\n",
    "                                      [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                                      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
    "matrices.append(zero_to_densitiy(close_call_matrix))\n",
    "\n",
    "# A few copies of the ideal matrix with a few random elements flipped\n",
    "random_matrix_1 = flip_random_elements(ideal_matrix)\n",
    "matrices.append(random_matrix_1)\n",
    "random_matrix_2 = flip_random_elements(ideal_matrix)\n",
    "matrices.append(random_matrix_2)\n",
    "random_matrix_3 = flip_random_elements(ideal_matrix)\n",
    "matrices.append(random_matrix_3)\n",
    "random_matrix_4 = flip_random_elements(ideal_matrix)\n",
    "matrices.append(random_matrix_4)\n",
    "random_matrix_5 = flip_random_elements(ideal_matrix)\n",
    "matrices.append(random_matrix_5)\n",
    "\n",
    "# for some reason the zero_to_density funcion only works if doing it twice\n",
    "matrices = list(map(lambda matrix: zero_to_densitiy(matrix), matrices))\n",
    "\n",
    "# Here we create a list of names for the different matrices\n",
    "matrix_names = [\"Filled\", \"Empty\", \"Random\", \"Half\", \"Ideal\", \"Less Ideal\", \"Broken\", \"Bad Design\", \"Heavy\", \"Close_Call\", \"Random 1\", \"Random 2\", \"Random 3\", \"Random 4\", \"Random 5\"]\n",
    "# init the dictionary\n",
    "matrix_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fill the dictionary with the matrices and their respective names\n",
    "# calculate the reward functions and compliance values\n",
    "# and add them to the states list\n",
    "for name, matrix in zip(matrix_names, matrices):\n",
    "    scaled_matrix= scale_matrix(matrix, height, width)\n",
    "    state = {\n",
    "        \"matrix\" : scaled_matrix, \n",
    "        \"Name\" : name, \n",
    "        \"rewardfunc\" : rewardFunction_old(scaled_matrix), \n",
    "        \"constraint\" : constraintFunction(scaled_matrix),\n",
    "        \"Compliance\" : objective(scaled_matrix), \n",
    "        \"continuous\" : is_continuous(scaled_matrix, bound_nodes_list + loaded_nodes_list),\n",
    "        \"filled_cells\" : get_filled_cells(scaled_matrix),\n",
    "        \"filled_ratio\": get_filled_cells(scaled_matrix) / number_of_nodes,\n",
    "        \"reward1\" : rewardFunction_1(scaled_matrix),\n",
    "        \"reward2\" : rewardFunction_2(scaled_matrix, get_compliance(scaled_matrix), \n",
    "                                     initial_compliance, get_compliance(scaled_matrix))\n",
    "    }\n",
    "    states.append(state)\n",
    "print(\"Different Matrices with their respective Reward Functions and Compliance Values:\")\n",
    "render_all(states)\n",
    "\n",
    "# reset the different lists for the second test run\n",
    "states.clear()\n",
    "matrices.clear()\n",
    "matrix_names.clear()\n",
    "matrix_dict.clear()\n",
    "\n",
    "# again for some reason zero_to_density only works if done twice\n",
    "ideal_matrix = zero_to_densitiy(ideal_matrix)\n",
    "matrices.append(zero_to_densitiy(ideal_matrix))\n",
    "\n",
    "# create a copy of the last matrix in the list, turn a random voided element\n",
    "# into a filled one and add it to the matrices list.\n",
    "# continue doing so to simulate 15 steps of a design process to analyse the\n",
    "# reward functions and compliance values\n",
    "for i in range(0, 15):\n",
    "    temp = turn_random_density_to_one(matrices[i])\n",
    "    temp = zero_to_densitiy(temp)\n",
    "    matrices.append(temp)\n",
    "\n",
    "# reverse the list of matrices to get the correct order\n",
    "matrices.reverse()\n",
    "matrix_names = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\"]\n",
    "print(bound_nodes_list)\n",
    "for name, matrix in zip(matrix_names, matrices):\n",
    "    scaled_matrix= scale_matrix(matrix, height, width)\n",
    "    state = {\n",
    "        \"matrix\" : scaled_matrix, \n",
    "        \"Name\" : name, \n",
    "        \"rewardfunc\" : rewardFunction_old(scaled_matrix), \n",
    "        \"constraint\" : constraintFunction(scaled_matrix),\n",
    "        \"Compliance\" : objective(scaled_matrix), \n",
    "        \"continuous\" : is_continuous(scaled_matrix, bound_nodes_list + loaded_nodes_list),\n",
    "        \"filled_cells\" : get_filled_cells(scaled_matrix),\n",
    "        \"filled_ratio\": get_filled_cells(scaled_matrix) / number_of_nodes,\n",
    "        \"reward1\" : rewardFunction_1(scaled_matrix),\n",
    "        \"reward2\" : rewardFunction_2(scaled_matrix, get_compliance(scaled_matrix), \n",
    "                                     initial_compliance, get_compliance(scaled_matrix))\n",
    "    }\n",
    "    states.append(state)\n",
    "print(\"Showcasing a Design Process with the Reward Functions and Compliance Values:\")\n",
    "render_all(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining the different Values\n",
    "\n",
    "- oldRewardfunction returns $\\sqrt{\\left(\\frac{1}{compliance}\\right)}$ with the compliance representing the elasticity of the design this is the original reward function by gigala\n",
    "- Compliance represents the current Elasticity Factor of the Design. It is the Inverse of the Stiffness\n",
    "- Constraint is the normalized volume of the design\n",
    "- Continuous is a Boolean representing if the Bounded Node is connected to the Node which has a force applied to it\n",
    "- Filled Cells is the Number of cells, which are currently filled in\n",
    "- Reward1 is the value of the naive rewardFunction written by me\n",
    "- Reward2 is the value of the modified reward function used by Nathan Brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning the Enviroment\n",
    "## Variables\n",
    "- __initial_compliance__\n",
    "    - This Variable will store the compliance Value of a completely filled in design space\n",
    "    - this is needed for the Reward function\n",
    "- __design_space:__\n",
    "    - This will be a Matrix consisting of filled and voided Elements, represented by ones and the density constant.\n",
    "    - It will have the Dimensions set in the Parameters Cell\n",
    "    - It should be initialized to be completely filled\n",
    "- __bound_nodes:__\n",
    "    - This will be a Matrix consisting of ones and zeros, representing which Elements are bounded\n",
    "    - It will be of the same Dimensions as design_space\n",
    "    - It will get the coordinates of bounded nodes from the bound_node_list in the Parameters Cell\n",
    "- __force_nodes:__\n",
    "    - This will be a Matrix consisting of ones and zeros, representing which Elements have a force applied to them\n",
    "    - It will be of the same Dimensions as design_space and bound_nodes\n",
    "    - It will get the coordinates of loaded nodes form the force_node_list in the Parameters Cell\n",
    "- __action_space__:\n",
    "    - This Variable is required by the gym Module for any Reinforcement Learning Enviroment\n",
    "    - It will tell training agent how many actions it can take.\n",
    "    - In our case it is going the be set as many discrete actions, as there are Elements in the Design Space\n",
    "- __actions_to_coordinates__:\n",
    "    - This will be a Dictionary with one key. The key being an Integer and the associated Value being a Tuple\n",
    "    - The Number will be incrementing from zero to number_of_nodes, which represents the amount of Elements in the design space\n",
    "    - This Number will be connected to a Tuple, representing the coordinates of an Element in the Design space\n",
    "    - This will make it poosible for the reinforcment learning agent to choose actions as simple Integers, which then will be equated to an Element in the Design Space\n",
    "    - In this way, choosing a number as action can be used to remove an Element from the Design Space\n",
    "    - Example: 0: (0,0), 1: (0, 1), 2: (1, 0), 3: (1, 1), ..... number_of_nodes: (height, width)\n",
    "- __performed_actions:__\n",
    "    - This will simply be a list that keeps track of which actions have previously been performed in this Episode\n",
    "    - It will be used as an Ending criteria, as well as in the rewarding of actions\n",
    "- __reward:__\n",
    "    - This Variable will simply keep track of the current reward of the Episode\n",
    "- __step_count__\n",
    "    - This Varuable will be used to count the number of steps that have taken place in this Episode\n",
    "    - might be used fot ending criteria or rewarding\n",
    "\n",
    "## Functions\n",
    "- __init(self)__\n",
    "    - This Function will initialize the Enviroment, so it will call the super constructor\n",
    "    - The Variables we should initialize here are:\n",
    "        - __design_space__ as matrix of dimensions __height__ and __width__, where every Element equals 1 \n",
    "        - __bound_nodes__ as matrix filled with ones and zeros according to __bound_nodes_list__\n",
    "        - __force_nodes__ as matrix filled with ones and zeros according to __force_nodes_list__\n",
    "        - __action_space__ as gym.spaces.Discrete Object with length __number_of_nodes__\n",
    "        - __observation_space__ as gym.spaces.Box Object with Dimensions __height__ and __width__\n",
    "        - __reward__ with value 0\n",
    "        - __step_count__ with value 0\n",
    "    - also the __actions_to_coordinates__ dictionary should be initialized \n",
    "    - lastly it should call the __reset(self)__ function to reset as well as initialize all the Values, that get set there.\n",
    "\n",
    "- __reset(self)__:\n",
    "    - This function will reset Variables, that need to be a certain Value at the beginning of an Episode to their correct inital Value\n",
    "    -\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback for saving a model (the check is done every ``check_freq`` steps)\n",
    "    based on the training reward (in practice, we recommend using ``EvalCallback``).\n",
    "\n",
    "    :param check_freq: (int)\n",
    "    :param log_dir: (str) Path to the folder where the model will be saved.\n",
    "      It must contains the file created by the ``Monitor`` wrapper.\n",
    "    :param verbose: (int)s\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, check_freq: int, log_dir: str, verbose=1):\n",
    "        super().__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.log_dir = log_dir\n",
    "        self.save_path = os.path.join(log_dir, \"best_model\")\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        # Create folder if needed\n",
    "        if self.save_path is not None:\n",
    "            # os.makedirs(self.save_path, exist_ok=True\n",
    "            return\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "\n",
    "            # Retrieve training reward\n",
    "            x, y = ts2xy(load_results(self.log_dir), \"timesteps\")\n",
    "            if len(x) > 0:\n",
    "                # Mean training reward over the last 100 episodes\n",
    "                mean_reward = np.mean(y[-100:])\n",
    "                if self.verbose > 0:\n",
    "                    print(\"---------------------------------------------------------\")\n",
    "                    print(f\"Num timesteps: {self.num_timesteps}\")\n",
    "                    print(\n",
    "                        f\"Best mean reward: {self.best_mean_reward:.2f} - Last mean reward per episode: {mean_reward:.2f}\"\n",
    "                    )\n",
    "\n",
    "                vecenv_render(env)\n",
    "                # New best model, you could save the agent here\n",
    "                if mean_reward > self.best_mean_reward:\n",
    "                    self.best_mean_reward = mean_reward\n",
    "                    # Example for saving best model\n",
    "                    if self.verbose > 0:\n",
    "                        print(f\"Saving new best model to {self.save_path}.zip\")\n",
    "                    self.model.save(self.save_path)\n",
    "                    \n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env = SubprocVecEnv([lambda: TopOptEnv() for _ in range(number_subprocesses)]) #### trying to multiprocess\n",
    "env = TopOptEnv()\n",
    "check_env(env, warn=True)\n",
    "\n",
    "# Logs will be saved in log_dir/monitor.csv\n",
    "#env = VecMonitor(env, log_dir)\n",
    "\n",
    "env = Monitor(env, log_dir)\n",
    "#check_env(env, warn=True)\n",
    "callback = SaveOnBestTrainingRewardCallback(check_freq=1000, log_dir=log_dir)\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "file_writer = tf.summary.create_file_writer(ts_board_dir)\n",
    "with file_writer.as_default():\n",
    "    tf.summary.graph(sess.graph)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vecenv_render(env):\n",
    "    plt.close()\n",
    "    design_spaces = env.env_method(\"getInfo\")\n",
    "    fig, axs = plt.subplots(1,number_subprocesses)\n",
    "    fig.set_size_inches(20, 10)\n",
    "    \n",
    "    for i in range(number_subprocesses):\n",
    "        axs[i].imshow(design_spaces[i][\"design_space\"],vmin=density, vmax=1)\n",
    "        current_reward = design_spaces[i][\"current_reward\"]\n",
    "        title = (str(i+1) + \"\\nReward= \" + str(round(current_reward, 1)))\n",
    "        axs[i].scatter(x_bound_positions_for_scatter, \n",
    "                       y_bound_positions_for_scatter, \n",
    "                       s=20, color='k', marker='x')\n",
    "\n",
    "        axs[i].scatter(x_loaded_positions_for_scatter, \n",
    "                       y_loaded_positions_for_scatter, \n",
    "                       s=20, color='k', marker='$↓$')\n",
    "        axs[i].set_title(title, fontsize=11, pad=10)\n",
    "        \n",
    "    \n",
    "    plt.show()    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ts_board_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "model = PPO(\"MlpPolicy\", env, tensorboard_log=ts_board_dir).learn(total_timesteps=ts, callback=callback)\n",
    "end=time.time()   \n",
    "print(\"Elapsed Time = \" + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()\n",
    "env = TopOptEnv(mode=\"eval\", threshold= 0.6)\n",
    "model_best = PPO.load(\"log/best_model\",env=env)\n",
    "obs, _ = env.reset()\n",
    "i=0\n",
    "while i<1000:\n",
    "    action, _states = model_best.predict(obs)\n",
    "    action = action.item()\n",
    "    print(f\"Step {i + 1}\")\n",
    "    # print(\"Action: \", action)       # added Console Outputs for better understanding  \n",
    "    obs, rewards, dones, _, info = env.step(action)\n",
    "    if i%10 == 0:\n",
    "        env.render()\n",
    "    if dones:\n",
    "        print(\"Goal reached!\", \"reward=\", rewards)\n",
    "        env.render()\n",
    "        break\n",
    "    i+=1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO test 5x10 with removing the plus 1 at the gigala normals matrix\n",
    "# \n",
    "# TODO Check different Compliance Thresholds\n",
    "# \n",
    "#\n",
    "# \n",
    "# TODO Comment comment comment\n",
    "# \n",
    "\n",
    "# TODO Scale the Fonts in the Vecenv_render Function accordingly to the design space size\n",
    "# \n",
    "# \n",
    "# Maybe add scaling to the reinforcement learning:\n",
    "# Scale the matrix down to where either width or height is the smallest common multiple of the two\n",
    "# get the \"rough shape\" from there, and then scale it up and removing the \"excess\" nodes\n",
    "# so it progressively refines the structure\n",
    "\n",
    "\n",
    "# Or maybe break the design space into smaller parts and then train the model on those\n",
    "# Where would the forces and Bounds Be?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
