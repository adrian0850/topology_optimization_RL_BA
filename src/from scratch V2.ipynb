{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "in this cell the used variables can be changed \n",
    "\n",
    "height and width correspond to the dimensions of the Workspace, in which the Topology Optimisation is going to be performed\n",
    "\n",
    "log_dir is the direction where the current best Model will be saved to during training\n",
    "\n",
    "ts is the amount of timesteps the model will be trained for\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "\n",
    "import autograd.numpy as anp\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common import results_plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalsX\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "normalsY\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "height = 13\n",
    "width = 19\n",
    "log_dir = \"log\"\n",
    "ts = 1e6\n",
    "\n",
    "density = 1e-4\n",
    "constraint_thresh = 0.7\n",
    "\n",
    "\n",
    "normals = np.zeros((height, width, 2))\n",
    "x = 0\n",
    "y = 1\n",
    "print(\"normalsX\\n\" + str(normals[:,:,x]))\n",
    "print(\"normalsY\\n\" + str(normals[:,:,y]))\n",
    "\n",
    "\n",
    "\n",
    "number_of_nodes = height * width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the reward for each state of the workspace is the compliance\n",
    "which should be minimized or above a certain threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO write the function to get the reward\n",
    "# It should return the compliance of the structure\n",
    "# The compliance is the sum of the forces applied to the structure\n",
    "# multiplied by the displacement of the nodes\n",
    "# The goal of the Optimization will be to minimize the compliance or keep it below a certain threshold\n",
    "\n",
    "\n",
    "def rewardFunction(state):\n",
    "    return 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def constraintFunction(state):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopOptEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self):\n",
    "        # The constructor of the environment\n",
    "\n",
    "        super().__init__()\n",
    "        self.design_space = anp.ones((height, width))\n",
    "        self.bound_nodes = np.zeros((height, width))\n",
    "        self.force_nodes = np.zeros((height, width))\n",
    "        self.density_matrix = self.design_space * density\n",
    "        \n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(number_of_nodes)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(height, width), dtype=np.float64)\n",
    "\n",
    "        # A Dictionary is used to map each coordinate tuple of the designspace to\n",
    "        # a singular distinct integer for use in the \n",
    "        k=0\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                self._actions_to_coordinates[k] = (i,j)\n",
    "                k += 1\n",
    "\n",
    "\n",
    "        print(\"self.n:\\t\" + str(self.n) + \"\\nself.m:\\t\" + str(self.m))\n",
    "        self._actions_to_coordinates = {} \n",
    "        self.reward = 0\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def step(self, action):\n",
    "        #\n",
    "        # TODO finisch the step function for the environment\t\n",
    "        # we need to add the reward function and the termination condition\n",
    "        #\n",
    "        #\n",
    "        # action is the coordinate of the node that is going to be changed\n",
    "        # action is a number between 0 and number_of_nodes\n",
    "\n",
    "        self.step_count += 1\n",
    "        terminated = False\n",
    "\n",
    "        #check if the selected Node is either bound or force node\n",
    "        if self.bound_nodes[self._actions_to_coordinates[action]] == 1:\n",
    "            self.reward = -1\n",
    "            return self.design_space, self.reward, terminated, False, self._getInfo()\n",
    "        \n",
    "        if self.force_nodes[self._actions_to_coordinates[action]] == 1:\n",
    "            self.reward = -1\n",
    "            return self.design_space, self.reward, terminated, False, self._getInfo()\n",
    "        \n",
    "        if self.design_space[self._actions_to_coordinates[action]] == 0:\n",
    "            self.reward = -1\n",
    "            return self.design_space, self.reward, terminated, False, self._getInfo()\n",
    "\n",
    "        # exectute an action and get the Reward\n",
    "        self.design_space[self._actions_to_coordinates[action]] = 0\n",
    "        self.reward = rewardFunction(self.design_space)\n",
    "        self.constraint = constraintFunction(self.design_space)\n",
    "\n",
    "        # \n",
    "        if self.constraint > constraint_thresh:\n",
    "            self.reward -= 1\n",
    "\n",
    "        \n",
    "        if self.step_count > number_of_nodes:\n",
    "            terminated = True\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        return self.design_space, self.reward, terminated, False, self._getInfo()\n",
    "    \n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        # Reset the environment\n",
    "        # This function returns the initial state of the environment\n",
    "        # The initial state should be a 2D array of size (height, width)\n",
    "        #\n",
    "\n",
    "\n",
    "        super().reset(seed=seed)\n",
    "        self.design_space = anp.ones((height, width))\n",
    "        self.density_matrix = self.design_space * density \n",
    "\n",
    "        self.constraint = constraintFunction(self.design_space)\n",
    "        self.reward = 0\n",
    "        self.step_count = 0\n",
    "\n",
    "        #initialize the bound and force nodes\n",
    "        self.bound_nodes = np.zeros((height, width))\n",
    "        self.force_nodes = np.zeros((height, width))\n",
    "        \n",
    "        # TODO: think about how force and bound nodes should be set\n",
    "        # should both be randomized on each reset?\n",
    "        # and if so how should they be randomized?\n",
    "\n",
    "        return self.design_space, self._getInfo()\n",
    "    \n",
    "\n",
    "    \n",
    "    def _getInfo(self):\n",
    "        # This function returns the information about the environment\n",
    "        # This function is used to monitor the environment\n",
    "        # The information should be a dictionary\n",
    "        # The dictionary should contain the following keys:\n",
    "        # - step_count: the number of steps that have been executed\n",
    "        # - current Reward: the reward of the current state\n",
    "        # - design_space: the current state of the environment\n",
    "        return {\"step_count\": self.step_count, \n",
    "                \"current Reward\": self.reward,\n",
    "                \"design_space\": self.design_space}\n",
    "    \n",
    "    def debug(self):\n",
    "        print(self.design_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TopOptEnv' object has no attribute 'n'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mTopOptEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m check_env(env, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m env\u001b[38;5;241m.\u001b[39mdebug()\n",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m, in \u001b[0;36mTopOptEnv.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# A Dictionary is used to map each coordinate tuple of the designspace to\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# a singular distinct integer for use in the \u001b[39;00m\n\u001b[0;32m     21\u001b[0m k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m):\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm):\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actions_to_coordinates[k] \u001b[38;5;241m=\u001b[39m (i,j)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TopOptEnv' object has no attribute 'n'"
     ]
    }
   ],
   "source": [
    "env = TopOptEnv()\n",
    "check_env(env, warn=True)\n",
    "env.debug()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
