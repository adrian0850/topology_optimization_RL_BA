{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "in this cell the used variables can be changed \n",
    "\n",
    "height and width correspond to the dimensions of the Workspace, in which the Topology Optimisation is going to be performed\n",
    "\n",
    "log_dir is the direction where the current best Model will be saved to during training\n",
    "\n",
    "ts is the amount of timesteps the model will be trained for\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import autograd.numpy as anp\n",
    "import scipy\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common import results_plotter\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, VecMonitor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the parameter for the Optimization\n",
    "\n",
    "# DESIGN SPACE PARAMETERS\n",
    "\n",
    "height = 5                             # The height of the design space\n",
    "width = 10                              # The width of the design space                   \n",
    "number_of_nodes = height * width        # The number of nodes in the design space\n",
    "bound_nodes_list = [(0, 0), (0, -1)]    # A list containing the coordinates of \n",
    "                                        # the bounded nodes\n",
    "\n",
    "\n",
    "# PHYSICAL PARAMETERS FOR THE FEM ANALYSIS\n",
    "\n",
    "filter_width = 1\n",
    "penal = 3.0\n",
    "young_min = 1e-9\n",
    "young = 1\n",
    "poisson = 0.3\n",
    "density = 1e-4\n",
    "constraint_thresh = 0.7\n",
    "\n",
    "\n",
    "# TECHNICAL PARAMETERS FOR THE REINFORCEMENT LEARNING\n",
    "\n",
    "number_subprocesses = 8     # The number of Threads to be used during the \n",
    "                            # learning process\n",
    "\n",
    "log_dir = \"log/\"            # The directory of where to save the best model\n",
    "\n",
    "ts = 5e6                    # The number of timesteps to be used during the \n",
    "                            # learning process\n",
    "\n",
    "\n",
    "\n",
    "# This is for the used FEM analysis taken from the Gigala repository\n",
    "# it saves the boundary nodes in a 3D array where the first two dimensions are \n",
    "# the coordinates of the node and the third dimension is the direction of the normal\n",
    "normals = np.zeros((height + 1, width + 1, 2))\n",
    "x = 0\n",
    "y = 1\n",
    "for coords in bound_nodes_list:\n",
    "    normals[coords[x], coords[y], x] = 1\n",
    "    normals[coords[x], coords[y], y] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "forces = np.zeros((height + 1, width + 1, 2))\n",
    "forces[-1, -1, y] = -1\n",
    "forces = forces.ravel()\n",
    "\n",
    "\n",
    "\n",
    "fixdofs = np.flatnonzero(normals.ravel())\n",
    "alldofs = np.arange(2 * (normals.shape[0]) * (normals.shape[1]))\n",
    "freedofs = np.sort(list(set(alldofs) - set(fixdofs)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path_calculix = \"E:/Bachelorarbeit/CalculiX/bConverged/CalculiX/ccx\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the reward for each state of the workspace is the compliance\n",
    "which should be minimized or above a certain threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x, volume_contraint=False, use_filter=True):\n",
    "    kwargs = dict(penal=penal, e_min=young_min, e_0=young)\n",
    "    x_phys = physical_density(x, volume_contraint=volume_contraint, use_filter=use_filter)\n",
    "    ke     = get_stiffness_matrix(young, poisson)  # stiffness matrix\n",
    "    u      = displace(x_phys, ke, forces, freedofs, fixdofs, **kwargs)\n",
    "    c      = compliance(x_phys, u, ke, **kwargs)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_solver(a_entries, a_indices, size, sym_pos):\n",
    "    # a is (usu.) symmetric positive; could solve 2x faster w/sksparse.cholmod.cholesky(a).solve_A\n",
    "    \n",
    "    a = scipy.sparse.coo_matrix((a_entries, a_indices), shape=(size,)*2).tocsc()\n",
    "\n",
    "    return scipy.sparse.linalg.splu(a).solve\n",
    "\n",
    "\n",
    "\n",
    "# @autograd.primitive\n",
    "def solve_coo(a_entries, a_indices, b, sym_pos=False):\n",
    "    solver = _get_solver(a_entries, a_indices, b.size, sym_pos)\n",
    "    return solver(b)\n",
    "\n",
    "def grad_solve_coo_entries(ans, a_entries, a_indices, b, sym_pos=False):\n",
    "    def jvp(grad_ans):\n",
    "        lambda_ = solve_coo(a_entries, a_indices if sym_pos else a_indices[::-1],\n",
    "                            grad_ans, sym_pos)\n",
    "        i, j = a_indices\n",
    "        return -lambda_[i] * ans[j]\n",
    "    return jvp\n",
    "\n",
    "\n",
    "def compliance(x_phys, u, ke, *, penal=3, e_min=1e-9, e_0=1):\n",
    "    nely, nelx = x_phys.shape\n",
    "    ely, elx = anp.meshgrid(range(nely), range(nelx))  # x, y coords for the index map\n",
    "\n",
    "    n1 = (nely+1)*(elx+0) + (ely+0)  # nodes\n",
    "    n2 = (nely+1)*(elx+1) + (ely+0)\n",
    "    n3 = (nely+1)*(elx+1) + (ely+1)\n",
    "    n4 = (nely+1)*(elx+0) + (ely+1)\n",
    "    all_ixs = anp.array([2*n1, 2*n1+1, 2*n2, 2*n2+1, 2*n3, 2*n3+1, 2*n4, 2*n4+1])\n",
    "    u_selected = u[all_ixs]  # select from u matrix\n",
    "\n",
    "    ke_u = anp.einsum('ij,jkl->ikl', ke, u_selected)  # compute x^penal * U.T @ ke @ U\n",
    "    ce = anp.einsum('ijk,ijk->jk', u_selected, ke_u)\n",
    "    C = young_modulus(x_phys, e_0, e_min, p=penal) * ce.T\n",
    "    return anp.sum(C)\n",
    "\n",
    "\n",
    "def get_stiffness_matrix(e, nu):  # e=young's modulus, nu=poisson coefficient\n",
    "    k = anp.array([1/2-nu/6, 1/8+nu/8, -1/4-nu/12, -1/8+3*nu/8,\n",
    "                -1/4+nu/12, -1/8-nu/8, nu/6, 1/8-3*nu/8])\n",
    "    return e/(1-nu**2)*anp.array([[k[0], k[1], k[2], k[3], k[4], k[5], k[6], k[7]],\n",
    "                               [k[1], k[0], k[7], k[6], k[5], k[4], k[3], k[2]],\n",
    "                               [k[2], k[7], k[0], k[5], k[6], k[3], k[4], k[1]],\n",
    "                               [k[3], k[6], k[5], k[0], k[7], k[2], k[1], k[4]],\n",
    "                               [k[4], k[5], k[6], k[7], k[0], k[1], k[2], k[3]],\n",
    "                               [k[5], k[4], k[3], k[2], k[1], k[0], k[7], k[6]],\n",
    "                               [k[6], k[3], k[4], k[1], k[2], k[7], k[0], k[5]],\n",
    "                               [k[7], k[2], k[1], k[4], k[3], k[6], k[5], k[0]]])\n",
    "\n",
    "\n",
    "def get_k(stiffness, ke):\n",
    "    # Constructs sparse stiffness matrix k (used in the displace fn)\n",
    "    # First, get position of the nodes of each element in the stiffness matrix\n",
    "    nely, nelx = stiffness.shape\n",
    "    ely, elx = anp.meshgrid(range(nely), range(nelx))  # x, y coords\n",
    "    ely, elx = ely.reshape(-1, 1), elx.reshape(-1, 1)\n",
    "\n",
    "    n1 = (nely+1)*(elx+0) + (ely+0)\n",
    "    n2 = (nely+1)*(elx+1) + (ely+0)\n",
    "    n3 = (nely+1)*(elx+1) + (ely+1)\n",
    "    n4 = (nely+1)*(elx+0) + (ely+1)\n",
    "    edof = anp.array([2*n1, 2*n1+1, 2*n2, 2*n2+1, 2*n3, 2*n3+1, 2*n4, 2*n4+1])\n",
    "    edof = edof.T[0]\n",
    "    x_list = anp.repeat(edof, 8)  # flat list pointer of each node in an element\n",
    "    y_list = anp.tile(edof, 8).flatten()  # flat list pointer of each node in elem\n",
    "\n",
    "    # make the global stiffness matrix K\n",
    "    kd = stiffness.T.reshape(nelx*nely, 1, 1)\n",
    "    value_list = (kd * anp.tile(ke, kd.shape)).flatten()\n",
    "    return value_list, y_list, x_list\n",
    "\n",
    "def displace(x_phys, ke, forces, freedofs, fixdofs, *, penal=3, e_min=1e-9, e_0=1):\n",
    "    # Displaces the load x using finite element techniques (solve_coo=most of runtime)\n",
    "    stiffness = young_modulus(x_phys, e_0, e_min, p=penal)\n",
    "    k_entries, k_ylist, k_xlist = get_k(stiffness, ke)\n",
    "\n",
    "    index_map, keep, indices = _get_dof_indices(freedofs, fixdofs, k_ylist, k_xlist)\n",
    "\n",
    "\n",
    "    u_nonzero = solve_coo(k_entries[keep], indices, forces[freedofs], sym_pos=True)\n",
    "    u_values = anp.concatenate([u_nonzero, anp.zeros(len(fixdofs))])\n",
    "    return u_values[index_map]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def young_modulus(x, e_0, e_min, p=3):\n",
    "    return e_min + x ** p * (e_0 - e_min)\n",
    "\n",
    "def physical_density(x,volume_contraint=False, use_filter=True):\n",
    "    x = 1 * x.reshape(height, width)  # reshape from 1D to 2D\n",
    "    return gaussian_filter(x, filter_width) if use_filter else x  # maybe filter\n",
    "\n",
    "def mean_density(x, volume_contraint=False, use_filter=True):\n",
    "    return anp.mean(physical_density(x, volume_contraint, use_filter))\n",
    "\n",
    "# @autograd.extend.primitive\n",
    "def gaussian_filter(x, width): # 2D gaussian blur/filter\n",
    "    return scipy.ndimage.gaussian_filter(x, width, mode='reflect')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _get_dof_indices(freedofs, fixdofs, k_xlist, k_ylist):\n",
    "    index_map = inverse_permutation(anp.concatenate([freedofs, fixdofs]))\n",
    "    keep = anp.isin(k_xlist, freedofs) & anp.isin(k_ylist, freedofs)\n",
    "    # Now we index an indexing array that is being indexed by the indices of k\n",
    "    i = index_map[k_ylist][keep]\n",
    "    j = index_map[k_xlist][keep]\n",
    "    return index_map, keep, anp.stack([i, j])\n",
    "\n",
    "def inverse_permutation(indices):  # reverses an index operation\n",
    "    inverse_perm = np.zeros(len(indices), dtype=anp.int64)\n",
    "    inverse_perm[indices] = np.arange(len(indices), dtype=anp.int64)\n",
    "    return inverse_perm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewardFunction_old(state):\n",
    "    reshape = lambda state: state.reshape(height, width)\n",
    "    objective_fn = lambda state: objective(reshape(state))\n",
    "    value = objective_fn(state)\n",
    "    return ((1/value)**0.5) *10\n",
    "# def rewarder(matrix):\n",
    "#     reward = 2 * rewardFunction(matrix)/(constraintFunction(matrix))\n",
    "#     if is_continuous(matrix, bound_nodes):\n",
    "#         #reward += 1/rewardFunction(matrix)\n",
    "#         reward += 0.6/ constraintFunction(matrix)\n",
    "#     return (int)((reward**20)/1000000000)\n",
    "\n",
    "def rewardFunction(matrix):\n",
    "    reshape = lambda state: state.reshape(height, width)\n",
    "    objective_fn = lambda state: objective(reshape(state))\n",
    "    value = objective_fn(matrix)\n",
    "    reward = 20 / (np.sqrt(value)*2) / (constraintFunction(matrix))\n",
    "    if is_continuous(matrix, bound_nodes):\n",
    "        reward += 0.6 / constraintFunction(matrix)\n",
    "    return (int)((reward**20)/0000)\n",
    "\n",
    "\n",
    "\n",
    "def get_filled_cells(matrix):\n",
    "    return sum(cell == 1 for row in matrix for cell in row)\n",
    "\n",
    "def is_continuous(matrix, bound_nodes):\n",
    "# This function is used to check if the shape in the design space is continuous\n",
    "# it uses a depth first search algorithm to check if all the filled cells are\n",
    "# connected to a specified start point (here the first bound node)\n",
    "    try:\n",
    "        start = tuple(np.argwhere(bound_nodes == 1)[0]) if np.any(bound_nodes == 1) else None\n",
    "        end = tuple(np.argwhere(forces == 1)[0]) if np.any(forces == 1) else None\n",
    "    except ValueError:\n",
    "        print(\"there are no bound Nodes given in the bound_nodes matrix\")\n",
    "        return False\n",
    "    filled_cells = get_filled_cells(matrix)\n",
    "    visited = dfs(matrix, start, end)\n",
    "    return len(visited) == filled_cells\n",
    " \n",
    "\n",
    "def dfs(matrix, start, end):\n",
    "# This function is the depth first search algorithm that is used to check if all\n",
    "# the filled cells in the design space are connected to a specified start point\n",
    "    rows, cols = len(matrix), len(matrix[0]) \n",
    "    visited = set() # Set to keep track of visited nodes    \n",
    "    stack = [start] # Start the stack with the start node\n",
    "    if not stack:  # Check if the stack is empty\n",
    "        raise RuntimeError(\"The stack is empty\")\n",
    "    while stack:\n",
    "        (row, col) = stack.pop()    # pop the last coordinates from the stack\n",
    "        if (row, col) == end:       # Check if the end point is reached\n",
    "            visited.add((row, col)) # Add the end point to the visited set\n",
    "            return visited          # Return the visited set\n",
    "        if (row < 0 or \n",
    "            row >= rows or \n",
    "            col < 0 or \n",
    "            col >= cols or \n",
    "            (row, col) in visited or \n",
    "            matrix[row][col] == 0): \n",
    "            #checking for discarding conditions\n",
    "            continue\n",
    "        visited.add((row, col))     # Add the current node to the visited set\n",
    "        stack.extend([(row-1, col), (row+1, col), (row, col-1), (row, col+1),\n",
    "                      (row-1, col-1), (row-1, col+1), (row+1, col-1), (row+1, col+1)])\n",
    "        # Add the neighbours of the current node to the stack\n",
    "    return visited\n",
    "\n",
    "\n",
    "def constraintFunction(state):\n",
    "    reshape = lambda state: state.reshape(height, width)\n",
    "    constraint = lambda params: mean_density(reshape(params)) \n",
    "    const = constraint(state)\n",
    "    return const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adrian\\AppData\\Local\\Temp\\ipykernel_2448\\4107257253.py:20: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return (int)((reward**20)/0000)\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "cannot convert float infinity to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 137\u001b[0m\n\u001b[0;32m    123\u001b[0m matrix_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, matrix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(matrix_names, matrices):\n\u001b[0;32m    129\u001b[0m     state \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatrix\u001b[39m\u001b[38;5;124m\"\u001b[39m : matrix, \n\u001b[0;32m    131\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m : name, \n\u001b[0;32m    132\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrewardfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m : rewardFunction_old(matrix), \n\u001b[0;32m    133\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstraint\u001b[39m\u001b[38;5;124m\"\u001b[39m : constraintFunction(matrix),\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompliance\u001b[39m\u001b[38;5;124m\"\u001b[39m : objective(matrix), \n\u001b[0;32m    135\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinuous\u001b[39m\u001b[38;5;124m\"\u001b[39m : is_continuous(matrix, bound_nodes),\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilled_cells\u001b[39m\u001b[38;5;124m\"\u001b[39m : get_filled_cells(matrix),\n\u001b[1;32m--> 137\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[43mrewardFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m     }\n\u001b[0;32m    139\u001b[0m     states\u001b[38;5;241m.\u001b[39mappend(state)\n\u001b[0;32m    143\u001b[0m render_all(states)\n",
      "Cell \u001b[1;32mIn[52], line 20\u001b[0m, in \u001b[0;36mrewardFunction\u001b[1;34m(matrix)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_continuous(matrix, bound_nodes):\n\u001b[0;32m     19\u001b[0m     reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.6\u001b[39m \u001b[38;5;241m/\u001b[39m constraintFunction(matrix)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreward\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOverflowError\u001b[0m: cannot convert float infinity to integer"
     ]
    }
   ],
   "source": [
    "#TESTING\n",
    "def render_all(states):\n",
    "    num_rows = 3\n",
    "    num_cols = 5\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(30, 15))\n",
    "    for i, state in enumerate(states):\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "        axs[row, col].imshow(states[i][\"matrix\"].reshape(height, width), vmin=density, vmax=1)\n",
    "        title = state[\"Name\"] + \"\\noldRewardfunction: \" + str(state[\"rewardfunc\"]) \n",
    "        title += \"\\nCompliance: \" + str(state[\"Compliance\"])\n",
    "        title += \"\\nConstraint: \" + str(state[\"constraint\"]) \n",
    "        title += \"\\nContinuous: \" + str(state[\"continuous\"])\n",
    "        title += \"\\nFilled Cells: \" + str(state[\"filled_cells\"])\n",
    "        title += \"\\nReward: \" + str(state[\"reward\"])\n",
    "        axs[row, col].set_title(title, fontsize=10, pad=20)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def flip_random_elements(matrix):\n",
    "    # Create a copy of the matrix\n",
    "    matrix_copy = np.copy(matrix)\n",
    "\n",
    "    # Get the shape of the matrix\n",
    "    rows, cols = matrix_copy.shape\n",
    "\n",
    "    # Determine the number of elements to flip\n",
    "    num_elements_to_flip = np.random.randint(1, rows*cols)\n",
    "\n",
    "    # Generate random indices\n",
    "    row_indices = np.random.randint(0, rows, num_elements_to_flip)\n",
    "    col_indices = np.random.randint(0, cols, num_elements_to_flip)\n",
    "\n",
    "    # Flip the elements at the generated indices\n",
    "    for row, col in zip(row_indices, col_indices):\n",
    "        matrix_copy[row, col] = 1 if matrix_copy[row, col] == density else density\n",
    "\n",
    "    return matrix_copy\n",
    "\n",
    "\n",
    "\n",
    "def zero_to_densitiy(matrix):\n",
    "    return np.where(matrix == 0, density, matrix)\n",
    "\n",
    "bound_nodes = np.zeros((height, width))\n",
    "for coord in bound_nodes_list:\n",
    "        bound_nodes[coord] = 1\n",
    "\n",
    "states = []\n",
    "matrices = []\n",
    "\n",
    "filled_matrix = np.ones((height, width))\n",
    "matrices.append(filled_matrix)\n",
    "\n",
    "empty_matrix = zero_to_densitiy(np.zeros((height, width)))\n",
    "matrices.append(zero_to_densitiy(empty_matrix))\n",
    "\n",
    "random_matrix = np.random.choice([density, 1], (height, width))\n",
    "matrices.append(random_matrix)\n",
    "\n",
    "half_matrix = zero_to_densitiy([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "                                [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
    "                                [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
    "                                [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                                [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
    "matrices.append(zero_to_densitiy(half_matrix))\n",
    "\n",
    "ideal_matrix = zero_to_densitiy([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
    "                                 [0, 0, 1, 0, 0, 0, 1, 1, 0, 0],\n",
    "                                 [0, 0, 0, 1, 0, 1, 0, 0, 1, 0],\n",
    "                                 [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
    "                                 [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
    "matrices.append(zero_to_densitiy(ideal_matrix))\n",
    "\n",
    "less_ideal_matrix = zero_to_densitiy([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                                      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
    "matrices.append(zero_to_densitiy(less_ideal_matrix))\n",
    "\n",
    "broken_matrix = zero_to_densitiy([[1, 1, 1, 1, 1, 0, 1, 0, 0, 0],\n",
    "                                  [0, 0, 1, 0, 0, 0, 1, 1, 0, 0],\n",
    "                                  [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
    "                                  [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
    "                                  [1, 1, 1, 1, 1, 0, 1, 1, 1, 1]])\n",
    "matrices.append(zero_to_densitiy(broken_matrix))\n",
    "\n",
    "bad_design = zero_to_densitiy([[1, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "                               [0, 0, 1, 0, 0, 0, 1, 1, 0, 0],\n",
    "                               [0, 0, 0, 1, 0, 1, 0, 0, 1, 0],\n",
    "                               [0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
    "                               [1, 1, 1, 1, 1, 0, 0, 0, 0, 1]])\n",
    "matrices.append(zero_to_densitiy(bad_design))\n",
    "\n",
    "heavy_matrix = zero_to_densitiy([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
    "                                 [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
    "                                 [1, 1, 1, 1, 1, 1, 0, 0, 1, 0],\n",
    "                                 [1, 1, 1, 1, 1, 0, 0, 0, 0, 1],\n",
    "                                 [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
    "matrices.append(zero_to_densitiy(heavy_matrix))\n",
    "\n",
    "close_call_matrix = zero_to_densitiy([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
    "                                      [0, 0, 1, 0, 0, 0, 1, 1, 0, 0],\n",
    "                                      [0, 0, 0, 1, 0, 1, 0, 0, 1, 0],\n",
    "                                      [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                                      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
    "matrices.append(zero_to_densitiy(close_call_matrix))\n",
    "random_matrix_1 = flip_random_elements(random_matrix)\n",
    "matrices.append(random_matrix_1)\n",
    "random_matrix_2 = flip_random_elements(random_matrix)\n",
    "matrices.append(random_matrix_2)\n",
    "random_matrix_3 = flip_random_elements(random_matrix)\n",
    "matrices.append(random_matrix_3)\n",
    "random_matrix_4 = flip_random_elements(random_matrix)\n",
    "matrices.append(random_matrix_4)\n",
    "random_matrix_5 = flip_random_elements(random_matrix)\n",
    "matrices.append(random_matrix_5)\n",
    "\n",
    "\n",
    "matrix_names = [\"Filled\", \"Empty\", \"Random\", \"Half\", \"Ideal\", \"Less Ideal\", \"Broken\", \"Bad Design\", \"Heavy\", \"Close_Call\", \"Random 1\", \"Random 2\", \"Random 3\", \"Random 4\", \"Random 5\"]\n",
    "\n",
    "matrix_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for name, matrix in zip(matrix_names, matrices):\n",
    "    state = {\n",
    "        \"matrix\" : matrix, \n",
    "        \"Name\" : name, \n",
    "        \"rewardfunc\" : rewardFunction_old(matrix), \n",
    "        \"constraint\" : constraintFunction(matrix),\n",
    "        \"Compliance\" : objective(matrix), \n",
    "        \"continuous\" : is_continuous(matrix, bound_nodes),\n",
    "        \"filled_cells\" : get_filled_cells(matrix),\n",
    "        \"reward\" : rewardFunction(matrix)\n",
    "    }\n",
    "    states.append(state)\n",
    "                \n",
    "\n",
    "\n",
    "render_all(states)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thoughts on training rewards\n",
    "\n",
    "- reward Function returns $\\sqrt{\\left(\\frac{1}{compliance}\\right)}$ with the compliance representing the elasticity of the design\n",
    "- constraint is the normalized volume of the design\n",
    "- being continuous should give a big boost in reward\n",
    "\n",
    "### quitting criteria\n",
    "\n",
    "- a function taking in both compliance as well as constraint $\\frac{Reward^{2}}{Constraint}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopOptEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        # The constructor of the environment\n",
    "        super().__init__()\n",
    "\n",
    "        # the design space is what contains the information about which cells\n",
    "        # are filled with material and which are not\n",
    "        self.design_space = anp.ones((height, width))\n",
    "\n",
    "        # the bound nodes matrix contains the information about which cells\n",
    "        # are fixed in place and which are not\n",
    "        self.bound_nodes = np.zeros((height, width))\n",
    "        for coord in bound_nodes_list:\n",
    "            self.bound_nodes[coord] = 1\n",
    "        \n",
    "        # the force nodes matrix contains the information about which cells\n",
    "        # have a force applied on them and which do not\n",
    "        self.force_nodes = np.zeros((height, width))\n",
    "        \n",
    "        \n",
    "        # Each Node in the Matrix is a performable action\n",
    "        self.action_space = gym.spaces.Discrete(number_of_nodes)\n",
    "        self.observation_space = gym.spaces.Box(low=0, \n",
    "                                                high=1, \n",
    "                                                shape=(height, width), \n",
    "                                                dtype=np.float64)\n",
    "\n",
    "        # A Dictionary is used to map each coordinate tuple of the designspace\n",
    "        # to a singular distinct integer for use in the optimization\n",
    "        # 0 = (0,0), 1 = (0,1), 2 = (0,2), ... , number_of_nodes = (height,width)\n",
    "        self._actions_to_coordinates = {}  \n",
    "        k=0\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                self._actions_to_coordinates[k] = (i,j)\n",
    "                k += 1\n",
    "\n",
    "\n",
    "        # initialize both the reward and the step count\n",
    "        self.reward = 0\n",
    "        self.step_count = 0\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def step(self, action):\n",
    "   \n",
    "        # actions are the coordinates of the node that is going to be changed\n",
    "        # action is a number between 0 and number_of_nodes\n",
    "\n",
    "        self.step_count += 1\n",
    "        terminated = False\n",
    "\n",
    "        # Check if the selected Action has already been performed on this state\n",
    "        if action in self.performed_actions:\n",
    "             self.reward= -100\n",
    "             return self.design_space, self.reward, terminated, False, self.getInfo()\n",
    "\n",
    "        #check if the selected Node is either bound or force node\n",
    "        print(self._actions_to_coordinates[action])\n",
    "        if self.bound_nodes[self._actions_to_coordinates[action]] == 1:\n",
    "            self.reward = -100\n",
    "            terminated = True\n",
    "            return self.design_space, self.reward, terminated, False, self.getInfo()\n",
    "        \n",
    "        if self.force_nodes[self._actions_to_coordinates[action]] == 1:\n",
    "            self.reward = -100\n",
    "            terminated = True\n",
    "            return self.design_space, self.reward, terminated, False, self.getInfo()\n",
    "        #Check if the selected Node is already removed\n",
    "        if self.design_space[self._actions_to_coordinates[action]] < 1:\n",
    "            self.reward = -100\n",
    "            terminated = True\n",
    "            return self.design_space, self.reward, terminated, False, self.getInfo()\n",
    "\n",
    "        if not is_continuous(self.design_space, self.bound_nodes):\n",
    "            self.reward = -100\n",
    "            terminated = True\n",
    "            return self.design_space, self.reward, terminated, False, self.getInfo()\n",
    "        \n",
    "        # exectute an action and get the Reward\n",
    "        self.remove_node(action)\n",
    "\n",
    "        self.reward += rewardFunction(self.design_space)\n",
    "        self.constraint = constraintFunction(self.design_space)\n",
    "        \n",
    "        # reward for removing nodes\n",
    "        # calculated by comparing the number of nodes in the design space with the number of nodes that are not zero\n",
    "        # basically: the less nodes that are one the better\n",
    "        # (multiplying the non_zero elements is to scale the reward)\n",
    "        self.reward += (np.size(self.design_space)-np.count_nonzero(self.design_space)) * np.size(self.design_space)\n",
    "        if is_continuous(self.design_space, self.bound_nodes):\n",
    "            self.reward += 1000\n",
    "        \n",
    "         \n",
    "        if self.constraint < constraint_thresh:\n",
    "            self.reward -= 1\n",
    "            terminated = True\n",
    "        \n",
    "        # If after having gone through as many steps as there are nodes\n",
    "        # the design isn't continuos the agent is punished and the episode ended\n",
    "        if self.step_count > number_of_nodes:\n",
    "            if not is_continuous(self.design_space, self.bound_nodes):\n",
    "                self.reward = -1000\n",
    "                terminated = True\n",
    "        \n",
    "        \n",
    "       \n",
    "        # add the current action to the list of performed actions\n",
    "        self.performed_actions.append(action)\n",
    "\n",
    "\n",
    "\n",
    "        return self.design_space, self.reward, terminated, False, self.getInfo()\n",
    "    \n",
    "\n",
    "    def remove_node(self, action):\n",
    "        self.design_space[self._actions_to_coordinates[action]] = density\n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        # Reset the environment\n",
    "        # This function returns the initial state of the environment\n",
    "        # The initial state should be a 2D array of size (height, width)\n",
    "        #\n",
    "        self.performed_actions = []\n",
    "\n",
    "        super().reset(seed=seed)\n",
    "        self.design_space = anp.ones((height, width))\n",
    "        \n",
    "        self.constraint = constraintFunction(self.design_space)\n",
    "        self.reward = 0\n",
    "        self.step_count = 0\n",
    "\n",
    "        # initialize the bound and force nodes\n",
    "        self.bound_nodes = np.zeros((height, width))\n",
    "        self.force_nodes = np.zeros((height, width))\n",
    "        \n",
    "        # We chose arbitrary but senseful Values here \n",
    "        # So this Enviroment wil train a Model, only fit to solve the problem\n",
    "        # that gets specified here\n",
    "        self.bound_nodes[0, 0] = 1\n",
    "        self.bound_nodes[0, -1] = 1\n",
    "        self.force_nodes[-1,-1] = 1\n",
    "\n",
    "        return self.design_space, self.getInfo()\n",
    "    \n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        # This function is used to render the environment\n",
    "        # This function is not necessary for the optimization\n",
    "        print(\"current Design\")\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(self.design_space)\n",
    "        plt.show()\n",
    "    \n",
    "    def getInfo(self):\n",
    "        # This function returns the information about the environment\n",
    "        # This function is used to monitor the environment\n",
    "        # The information should be a dictionary\n",
    "        # The dictionary should contain the following keys:\n",
    "        # - step_count: the number of steps that have been executed\n",
    "        # - current Reward: the reward of the current state\n",
    "        # - design_space: the current state of the environment\n",
    "        return {\"step_count\": self.step_count, \n",
    "                \"current_reward\": self.reward,\n",
    "                \"design_space\": self.design_space}\n",
    "    \n",
    "    def debug(self):\n",
    "        print(self.design_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback for saving a model (the check is done every ``check_freq`` steps)\n",
    "    based on the training reward (in practice, we recommend using ``EvalCallback``).\n",
    "\n",
    "    :param check_freq: (int)\n",
    "    :param log_dir: (str) Path to the folder where the model will be saved.\n",
    "      It must contains the file created by the ``Monitor`` wrapper.\n",
    "    :param verbose: (int)s\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, check_freq: int, log_dir: str, verbose=1):\n",
    "        super().__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.log_dir = log_dir\n",
    "        self.save_path = os.path.join(log_dir, \"best_model\")\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        # Create folder if needed\n",
    "        if self.save_path is not None:\n",
    "            # os.makedirs(self.save_path, exist_ok=True\n",
    "            return\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "\n",
    "            # Retrieve training reward\n",
    "            x, y = ts2xy(load_results(self.log_dir), \"timesteps\")\n",
    "            if len(x) > 0:\n",
    "                # Mean training reward over the last 100 episodes\n",
    "                mean_reward = np.mean(y[-100:])\n",
    "                if self.verbose > 0:\n",
    "                    print(f\"Num timesteps: {self.num_timesteps}\")\n",
    "                    print(\n",
    "                        f\"Best mean reward: {self.best_mean_reward:.2f} - Last mean reward per episode: {mean_reward:.2f}\"\n",
    "                    )\n",
    "\n",
    "                vecenv_render(env)\n",
    "                # New best model, you could save the agent here\n",
    "                if mean_reward > self.best_mean_reward:\n",
    "                    self.best_mean_reward = mean_reward\n",
    "                    # Example for saving best model\n",
    "                    if self.verbose > 0:\n",
    "                        print(f\"Saving new best model to {self.save_path}.zip\")\n",
    "                    self.model.save(self.save_path)\n",
    "                    \n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SubprocVecEnv([lambda: TopOptEnv() for _ in range(number_subprocesses)]) #### trying to multiprocess\n",
    "#env = TopOptEnv()\n",
    "#check_env(env, warn=True)\n",
    "\n",
    "# Logs will be saved in log_dir/monitor.csv\n",
    "env = VecMonitor(env, log_dir)\n",
    "\n",
    "#env = Monitor(env, log_dir)\n",
    "#check_env(env, warn=True)\n",
    "callback = SaveOnBestTrainingRewardCallback(check_freq=1000, log_dir=log_dir)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vecenv_render(env):\n",
    "    plt.close()\n",
    "    design_spaces = env.env_method(\"getInfo\")\n",
    "    fig, axs = plt.subplots(1,number_subprocesses)\n",
    "    fig.set_size_inches(20, 10)\n",
    "    \n",
    "    for i in range(number_subprocesses):\n",
    "        axs[i].imshow(design_spaces[i][\"design_space\"],vmin=density, vmax=1)\n",
    "        axs[i].set_title(i+1)\n",
    "    \n",
    "    plt.show()    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "model = PPO(\"MlpPolicy\", env).learn(total_timesteps=ts, callback=callback)\n",
    "end=time.time()   \n",
    "print(\"Elapsed Time = \" + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()\n",
    "env = TopOptEnv()\n",
    "model_best = PPO.load(\"log/best_model\",env=env)\n",
    "obs, _ = env.reset()\n",
    "i=0\n",
    "while i<1000:\n",
    "    action, _states = model_best.predict(obs)\n",
    "    action = action.item()\n",
    "    print(f\"Step {i + 1}\")\n",
    "    # print(\"Action: \", action)       # added Console Outputs for better understanding  \n",
    "    obs, rewards, dones, _, info = env.step(action)\n",
    "    if i%10 == 0:\n",
    "        env.render()\n",
    "    # if dones:\n",
    "    #     print(\"Goal reached!\", \"reward=\", rewards)\n",
    "    #     break\n",
    "    i+=1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO test and debuo bjective function and all components(displace stiffnes physical density) with predetermined designs\n",
    "# wth smaller design spaces\n",
    "# TODO again the same but within the TopOptEnv\n",
    "\n",
    "# maybe export the topoptenv as python script \n",
    "# for debugging\n",
    "# \n",
    "# import into terminal \n",
    "#  \n",
    "# Markdown Notizen für nächste"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
